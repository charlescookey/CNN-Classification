{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049ea944-9725-4148-b1ac-b89159e7aeac",
   "metadata": {},
   "source": [
    "## 0. Import Packages:\n",
    "First, we import all the packages we want to use in our implementation:\n",
    "* A library to use operating system dependent functionality\n",
    "* Package imaging library to deal with images in Python (PIL)\n",
    "* Package to find all paths which matches a specified pattern (glob)\n",
    "* Numpy Package (numpy)\n",
    "* PyTorch Framework (torch)\n",
    "* Neural Network Library of PyTorch (torch.nn)\n",
    "* PyTorch Optimisation Package (torch.optim)\n",
    "* PyTorch dataset loader package (torchvision.datasets)\n",
    "* PyTorch package for image preprocessing (torchvision.transforms)\n",
    "* A library to loop through the csv file (pandas)\n",
    "* A library for image manpulation (opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66ebafd5-fb57-4037-b8d9-fda115fa29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets as dsets\n",
    "from torchvision import transforms as trans\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a0311-84cb-47a7-9b6d-ec8eca146be7",
   "metadata": {},
   "source": [
    "## 3. Set Hyperparameters:\n",
    "Hyperparameters are settings that can be tuned to control the behaviour of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bbace5b-f60c-45e4-971d-8f547f285d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters (Note: These values are not the optimal ones)\n",
    "batch_size = 16\n",
    "learning_rate = 0.1\n",
    "itr = 20 \n",
    "transformType = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac77d53b-338a-4ac4-8092-1ca37da99b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_image_size(root_folder):\n",
    "    max_width, max_height = 0, 0\n",
    "    image_paths = glob(os.path.join(root_folder, '**', '*.png'), recursive=True)\n",
    "\n",
    "    for path in image_paths:\n",
    "        with Image.open(path) as img:\n",
    "            width, height = img.size\n",
    "            max_width = max(max_width, width)\n",
    "            max_height = max(max_height, height)\n",
    "\n",
    "    return max_width, max_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f070707-9f8f-45c9-8d6a-6977efd6a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Image Size: 304x641\n"
     ]
    }
   ],
   "source": [
    "split_folder = 'dataset/split_dataset/'\n",
    "image_size  = None\n",
    "SizeY = 0\n",
    "\n",
    "# Define transformation\n",
    "transforms_resize = trans.Compose([trans.Grayscale(), trans.Resize([32,32]), trans.ToTensor(), trans.Normalize(mean=(0.5,), std = (0.5,))])\n",
    "\n",
    "max_width, max_height = get_max_image_size(split_folder)\n",
    "print(f\"Max Image Size: {max_width}x{max_height}\")\n",
    "target_size = (max_width, max_height)\n",
    "\n",
    "# Define the CenterCrop transform\n",
    "transforms_pad = trans.Compose([trans.Grayscale(), trans.CenterCrop(target_size), trans.ToTensor(),trans.Normalize(mean=(0.5,), std = (0.5,))\n",
    "])\n",
    "\n",
    "transforms_no_resize = trans.Compose([trans.Grayscale(), trans.ToTensor(),trans.Normalize(mean=(0.5,), std = (0.5,))\n",
    "])\n",
    "\n",
    "transforms = None\n",
    "\n",
    "\n",
    "if transformType == 1:\n",
    "    transforms = transforms_resize\n",
    "    image_size = (32, 32)\n",
    "elif transformType == 2:\n",
    "    transforms = transforms_pad\n",
    "    image_size = (max_width, max_height)\n",
    "else:\n",
    "    transforms = transforms_no_resize\n",
    "    image_size = (0, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9fea958c-c378-47ff-aa6c-96b83c24dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, TransformType):\n",
    "        super(ConvNet, self).__init__() \n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.TransformType = TransformType\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "        \t                   out_channels=6,\n",
    "            \t\t\t\t   kernel_size=(5,5),\n",
    "            \t\t\t\t   stride=(1,1))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=6,\n",
    "        \t                   out_channels=16,\n",
    "            \t\t\t\t   kernel_size=(5,5),\n",
    "            \t\t\t\t   stride=(1,1))\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.conv5 = nn.Conv2d(in_channels=16,\n",
    "        \t                   out_channels=120,\n",
    "            \t\t\t\t   kernel_size=(5,5),\n",
    "            \t\t\t\t   stride=(1,1))\n",
    "\n",
    "        if self.TransformType == 3:\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "            self.fc6 = nn.Linear(in_features=120,\n",
    "            \t\t\t     out_features=60)\n",
    "        elif self.TransformType == 4:\n",
    "            self.global_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "            self.fc6 = nn.Linear(in_features=120,\n",
    "            \t\t\t     out_features=60)\n",
    "        else:\n",
    "            self.flattened_size = self._get_flattened_size()\n",
    "            self.fc6 = nn.Linear(in_features=self.flattened_size,\n",
    "            \t\t\t     out_features=60)\n",
    "            \n",
    "        self.fc7 = nn.Linear(in_features=60,\n",
    "            \t\t\t     out_features=20)\n",
    "        self.fc8 = nn.Linear(in_features=20,\n",
    "            \t\t\t     out_features=4)\n",
    "    def _get_flattened_size(self):\n",
    "        # Create a dummy input to compute the size after convolutional and pooling layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, *self.input_size)  # Batch size of 1, 1 channel\n",
    "            dummy_output = self.pool4(self.conv3(self.pool2(self.conv1(dummy_input))))\n",
    "            dummy_output = self.conv5(dummy_output)\n",
    "            flattened_size = dummy_output.view(1, -1).size(1)  # Flatten and get the size\n",
    "        return flattened_size\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x = x.view([-1, 1, SizeX, SizeY])\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.pool2(x)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.pool4(x)\n",
    "        x = nn.functional.relu(self.conv5(x))\n",
    "\n",
    "        if self.TransformType == 3 or self.TransformType == 4:\n",
    "            x = self.global_pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        else:\n",
    "            x = x.view(-1, self.flattened_size)\n",
    "            \n",
    "        x = nn.functional.relu(self.fc6(x))\n",
    "        x = nn.functional.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77c36578-99c4-4134-ae5f-013a33af4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available() and cuda:\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    FloatType = torch.cuda.FloatTensor\n",
    "    LongType = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatType = torch.FloatTensor\n",
    "    LongType = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d85a543e-403f-4b14-8e74-fd2eccdc89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.normal_(mean=0,std=1e-2)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.normal_(mean=0,std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "da567309-7fff-4d7b-a62f-1e2613240202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 601, Validation Samples: 75, Test Samples: 78\n"
     ]
    }
   ],
   "source": [
    "class MIDSDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.paths = glob(os.path.join(self.root, '**', \"*.png\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = self.transform(Image.open(path))\n",
    "        label = int(path.split(os.path.sep)[-2])\n",
    "        return img, label\n",
    "\n",
    "# Create Subsets for PyTorch DataLoader\n",
    "train_dataset = MIDSDataset(root = os.path.join(split_folder, 'train'), transform= transforms)\n",
    "val_dataset = MIDSDataset(root = os.path.join(split_folder, 'val'), transform= transforms)\n",
    "test_dataset = MIDSDataset(root = os.path.join(split_folder, 'test'), transform= transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers = 0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = 0)\n",
    "\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train Samples: {len(train_dataset)}, Validation Samples: {len(val_dataset)}, Test Samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8508c0a-3999-4254-b3b6-0fb68b02fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, loss_func, epoch, scheduler=None, vis_step = 5):\n",
    "    # Number of samples with correct classification\n",
    "    num_hit = 0\n",
    "    # total size of train data\n",
    "    total = len(train_loader.dataset)\n",
    "    # number of batch\n",
    "    num_batch = np.ceil(total/batch_size)\n",
    "    accumulative_loss = 0\n",
    "    # Training loop over batches of data on train dataset\n",
    "    for batch_idx, (image, labels) in enumerate(train_loader):\n",
    "        # 1. Clearing previous gradient values.\n",
    "        optimizer.zero_grad()\n",
    "        # 2. feeding images to model (forward method will be computed)\n",
    "        output = model(image)\n",
    "        # 3. Calculating the loss value\n",
    "        loss = loss_func(output, labels)\n",
    "        # 4. Calculating new grdients given the loss value\n",
    "        loss.backward()\n",
    "        # 5. Updating the weights\n",
    "        optimizer.step()\n",
    "        # 6. logging (Optional)\n",
    "        if batch_idx % vis_step == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(image),\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss.data.item()))\n",
    "    # Validation Phase on train dataset\n",
    "    for batch_idx, (image, labels) in enumerate(train_loader):\n",
    "        output = model(image)\n",
    "        _ , pred_label = output.data.max(dim=1)\n",
    "        num_hit += (pred_label == labels.data).sum()\n",
    "    train_accuracy = (num_hit.item() / total)\n",
    "    print(\"Epoch: {}, Training Accuracy: {:.2f}%\".format(epoch, 100. * train_accuracy))\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(train_accuracy)\n",
    "    \n",
    "    return 100. * train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54c8ec5f-297f-4eca-8bbe-c42915d4f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_val(model, val_loader, epoch):\n",
    "    num_hit = 0\n",
    "    total = len(test_loader.dataset)\n",
    "\n",
    "    for batch_idx, (image, labels) in enumerate(val_loader): # Complete the rest of this function\n",
    "        output = model(image)\n",
    "        _ , pred_label = output.data.max(dim=1)\n",
    "        num_hit += (pred_label == labels.data).sum()\n",
    "    test_accuracy = (num_hit.item() / total)\n",
    "    print(\"Epoch: {}, Validation Accuracy: {:.2f}%\".format(epoch, 100. * test_accuracy))\n",
    "    return 100. * test_accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec90e9b1-94f3-41a8-9e62-beda8e8aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_test(model, test_loader, epoch):\n",
    "    num_hit = 0\n",
    "    total = len(test_loader.dataset)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_idx, (image, labels) in enumerate(test_loader):\n",
    "        output = model(image)\n",
    "        _, pred_label = output.data.max(dim=1)\n",
    "        num_hit += (pred_label == labels.data).sum()\n",
    "        all_preds.extend(pred_label.cpu().numpy())\n",
    "        all_labels.extend(labels.data.cpu().numpy())\n",
    "\n",
    "    test_accuracy = (num_hit.item() / total)\n",
    "    print(\"Epoch: {}, Testing Accuracy: {:.2f}%\".format(epoch, 100. * test_accuracy))\n",
    "    return 100. * test_accuracy, all_preds, all_labels\n",
    "\n",
    "def final_evaluation(all_preds, all_labels):\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(\"Final Evaluation Metrics:\")\n",
    "    print(\"Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(precision*100, recall*100, f1*100))\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    # Analyze confusion matrix for class-specific performance\n",
    "    class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(\"Class {} Accuracy: {:.2f}%\".format(i, 100. * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7099b41f-1399-4439-ae67-8ea795ebe4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(model, optimizer, scheduler):\n",
    "    torch.manual_seed(0)\n",
    "    # Training Hyperparameters\n",
    "    batch_size = 32 \n",
    "    learning_rate = 0.01\n",
    "    itr = 20 \n",
    "    \n",
    "    # for running on gpu\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # 2. Initialize model's weight\n",
    "    model.apply(weights_init)\n",
    "    \n",
    "    # 3. Define optimizer and loss function\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 4. Write the training loop\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    total_time = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for epoch in range(itr):\n",
    "        start = time()\n",
    "        tr_acc = train_model(model, optimizer, train_loader, loss_func, epoch+1, scheduler)\n",
    "        vs_acc = eval_model_val(model, val_loader, epoch+1)\n",
    "        ts_acc, epoch_preds, epoch_labels = eval_model_test(model, test_loader,epoch+1)\n",
    "        train_acc.append(tr_acc)\n",
    "        test_acc.append(ts_acc)\n",
    "        all_preds.extend(epoch_preds)\n",
    "        all_labels.extend(epoch_labels)\n",
    "        end = time()\n",
    "        total_time += end-start\n",
    "    print(\"Training and evaluation finished in:\", total_time, \"sec.\")\n",
    "    final_evaluation(all_preds, all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68807042-6399-4203-baa0-e6d8c6838d53",
   "metadata": {},
   "source": [
    "transform type =1\n",
    "we resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a18b45a9-3ac2-4877-8529-497eb9138df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 2.703585\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.284705\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.306450\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.356872\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.572598\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 0.938165\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.244697\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 0.948339\n",
      "Epoch: 1, Training Accuracy: 51.25%\n",
      "Epoch: 1, Validation Accuracy: 50.00%\n",
      "Epoch: 1, Testing Accuracy: 53.85%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.160579\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.115921\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 1.079053\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.278095\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 1.947712\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 0.961217\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 1.104916\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 0.985849\n",
      "Epoch: 2, Training Accuracy: 59.07%\n",
      "Epoch: 2, Validation Accuracy: 58.97%\n",
      "Epoch: 2, Testing Accuracy: 57.69%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 1.059262\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 0.927496\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 0.961280\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 0.723095\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 0.710484\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 1.164935\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 0.903747\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 0.638188\n",
      "Epoch: 3, Training Accuracy: 54.24%\n",
      "Epoch: 3, Validation Accuracy: 52.56%\n",
      "Epoch: 3, Testing Accuracy: 55.13%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 1.123638\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 0.780015\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 0.634156\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 0.710729\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 0.595116\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 0.820889\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 0.570203\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 0.919779\n",
      "Epoch: 4, Training Accuracy: 70.22%\n",
      "Epoch: 4, Validation Accuracy: 65.38%\n",
      "Epoch: 4, Testing Accuracy: 61.54%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 0.776220\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 0.502284\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 0.869653\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 1.289002\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 0.373683\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 0.651750\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 1.058709\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 0.137134\n",
      "Epoch: 5, Training Accuracy: 67.39%\n",
      "Epoch: 5, Validation Accuracy: 61.54%\n",
      "Epoch: 5, Testing Accuracy: 60.26%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 0.586634\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 0.549285\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 0.218806\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 0.303343\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 0.455164\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 0.632204\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 0.863969\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 0.555170\n",
      "Epoch: 6, Training Accuracy: 77.37%\n",
      "Epoch: 6, Validation Accuracy: 69.23%\n",
      "Epoch: 6, Testing Accuracy: 75.64%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 0.432668\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 0.371963\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 0.476046\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 0.447812\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 0.414587\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 0.231350\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 0.438897\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 0.360193\n",
      "Epoch: 7, Training Accuracy: 85.86%\n",
      "Epoch: 7, Validation Accuracy: 79.49%\n",
      "Epoch: 7, Testing Accuracy: 85.90%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 0.485606\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 0.208054\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 0.217732\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 0.243673\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 0.956669\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 0.251036\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 0.120478\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 0.313802\n",
      "Epoch: 8, Training Accuracy: 80.70%\n",
      "Epoch: 8, Validation Accuracy: 73.08%\n",
      "Epoch: 8, Testing Accuracy: 78.21%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 0.112581\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 0.055437\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 0.154506\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 0.187795\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 0.073103\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 0.176252\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 0.629196\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 0.447128\n",
      "Epoch: 9, Training Accuracy: 86.19%\n",
      "Epoch: 9, Validation Accuracy: 78.21%\n",
      "Epoch: 9, Testing Accuracy: 83.33%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 0.499029\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 0.141231\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 0.156334\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 0.192293\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 0.108190\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 0.078244\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 0.047560\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 0.111102\n",
      "Epoch: 10, Training Accuracy: 97.34%\n",
      "Epoch: 10, Validation Accuracy: 82.05%\n",
      "Epoch: 10, Testing Accuracy: 87.18%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 0.244264\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 0.139127\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 0.081763\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 0.211675\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 0.034895\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 0.216191\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 0.069447\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 0.232952\n",
      "Epoch: 11, Training Accuracy: 85.86%\n",
      "Epoch: 11, Validation Accuracy: 67.95%\n",
      "Epoch: 11, Testing Accuracy: 80.77%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 1.129286\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 0.032766\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 0.070688\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 0.438170\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 0.082236\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 0.088108\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 0.337234\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 0.216466\n",
      "Epoch: 12, Training Accuracy: 94.34%\n",
      "Epoch: 12, Validation Accuracy: 82.05%\n",
      "Epoch: 12, Testing Accuracy: 83.33%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 0.315715\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 0.247960\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 0.067942\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 0.090853\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 0.048836\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 0.003718\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 0.205244\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 0.323761\n",
      "Epoch: 13, Training Accuracy: 95.51%\n",
      "Epoch: 13, Validation Accuracy: 76.92%\n",
      "Epoch: 13, Testing Accuracy: 82.05%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 0.132223\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 0.065154\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 0.334447\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 0.020344\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 0.142147\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 0.086599\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 0.120796\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 0.015324\n",
      "Epoch: 14, Training Accuracy: 99.33%\n",
      "Epoch: 14, Validation Accuracy: 83.33%\n",
      "Epoch: 14, Testing Accuracy: 85.90%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 0.051527\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 0.103342\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 0.097888\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 0.015225\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 0.011928\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 0.006387\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 0.003459\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 0.010712\n",
      "Epoch: 15, Training Accuracy: 99.17%\n",
      "Epoch: 15, Validation Accuracy: 80.77%\n",
      "Epoch: 15, Testing Accuracy: 88.46%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 0.022499\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 0.006525\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 0.108814\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 0.091669\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 0.015987\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 0.005985\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 0.000330\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 0.001346\n",
      "Epoch: 16, Training Accuracy: 99.67%\n",
      "Epoch: 16, Validation Accuracy: 85.90%\n",
      "Epoch: 16, Testing Accuracy: 88.46%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 0.005402\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 0.006730\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 0.002260\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 0.002666\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 0.000932\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 0.001193\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 0.000212\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 0.001562\n",
      "Epoch: 17, Training Accuracy: 100.00%\n",
      "Epoch: 17, Validation Accuracy: 79.49%\n",
      "Epoch: 17, Testing Accuracy: 92.31%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 0.026040\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 0.002711\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 0.003165\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 0.000144\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 0.000608\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 0.000665\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 0.002173\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 0.000913\n",
      "Epoch: 18, Training Accuracy: 100.00%\n",
      "Epoch: 18, Validation Accuracy: 83.33%\n",
      "Epoch: 18, Testing Accuracy: 88.46%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 0.000939\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 0.000224\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 0.002324\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 0.001560\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 0.000575\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 0.000294\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 0.000182\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 0.000665\n",
      "Epoch: 19, Training Accuracy: 100.00%\n",
      "Epoch: 19, Validation Accuracy: 83.33%\n",
      "Epoch: 19, Testing Accuracy: 88.46%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 0.002316\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 0.000267\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 0.000424\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 0.000237\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 0.000127\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 0.003275\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 0.000393\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 0.003185\n",
      "Epoch: 20, Training Accuracy: 100.00%\n",
      "Epoch: 20, Validation Accuracy: 84.62%\n",
      "Epoch: 20, Testing Accuracy: 89.74%\n",
      "Training and evaluation finished in: 29.85820508003235 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 78.93, Recall: 78.33, F1-Score: 78.53\n",
      "Confusion Matrix:\n",
      "[[252  47  23  18]\n",
      " [ 11 276   1  92]\n",
      " [ 32   4 378   6]\n",
      " [ 13  91   0 316]]\n",
      "Class 0 Accuracy: 74.12%\n",
      "Class 1 Accuracy: 72.63%\n",
      "Class 2 Accuracy: 90.00%\n",
      "Class 3 Accuracy: 75.24%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(image_size , 1)\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)\n",
    "runModel(model, optimizer, None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18e048b6-dd83-4498-86ec-a07908d1e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 2.472919\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.501659\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.279527\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.310018\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.153296\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 1.187111\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.420956\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 1.096948\n",
      "Epoch: 1, Training Accuracy: 47.59%\n",
      "Epoch: 1, Validation Accuracy: 42.31%\n",
      "Epoch: 1, Testing Accuracy: 48.72%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.028374\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.035772\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 1.007012\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.350958\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 0.866009\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 1.218280\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 1.269423\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 1.230453\n",
      "Epoch: 2, Training Accuracy: 49.42%\n",
      "Epoch: 2, Validation Accuracy: 41.03%\n",
      "Epoch: 2, Testing Accuracy: 48.72%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 0.798735\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 0.800655\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 0.949566\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 0.907098\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 1.108216\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 0.884633\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 0.800425\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 0.741384\n",
      "Epoch: 3, Training Accuracy: 57.24%\n",
      "Epoch: 3, Validation Accuracy: 44.87%\n",
      "Epoch: 3, Testing Accuracy: 55.13%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 0.837518\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 0.789788\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 0.859082\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 0.917958\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 0.725850\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 1.189976\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 0.841041\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 0.896546\n",
      "Epoch: 4, Training Accuracy: 65.72%\n",
      "Epoch: 4, Validation Accuracy: 51.28%\n",
      "Epoch: 4, Testing Accuracy: 60.26%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 0.912816\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 0.762046\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 0.677378\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 0.786746\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 0.729221\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 0.828567\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 0.777943\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 0.676184\n",
      "Epoch: 5, Training Accuracy: 65.39%\n",
      "Epoch: 5, Validation Accuracy: 53.85%\n",
      "Epoch: 5, Testing Accuracy: 60.26%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 0.552860\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 0.766662\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 0.647286\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 0.787599\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 8.073426\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 1.008894\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 0.890264\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 0.867539\n",
      "Epoch: 6, Training Accuracy: 59.23%\n",
      "Epoch: 6, Validation Accuracy: 48.72%\n",
      "Epoch: 6, Testing Accuracy: 58.97%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 1.047483\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 0.802289\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 0.863958\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 0.814360\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 0.509715\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 0.620940\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 0.798352\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 0.534224\n",
      "Epoch: 7, Training Accuracy: 67.22%\n",
      "Epoch: 7, Validation Accuracy: 55.13%\n",
      "Epoch: 7, Testing Accuracy: 64.10%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 0.702301\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 0.464531\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 0.454813\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 0.565265\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 0.470235\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 0.612589\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 1.002858\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 0.656345\n",
      "Epoch: 8, Training Accuracy: 74.88%\n",
      "Epoch: 8, Validation Accuracy: 58.97%\n",
      "Epoch: 8, Testing Accuracy: 58.97%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 0.593723\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 0.541205\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 0.483826\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 0.556377\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 0.608003\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 0.484222\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 0.958341\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 0.721884\n",
      "Epoch: 9, Training Accuracy: 77.54%\n",
      "Epoch: 9, Validation Accuracy: 61.54%\n",
      "Epoch: 9, Testing Accuracy: 64.10%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 0.474751\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 0.498789\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 0.549240\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 0.241990\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 0.365868\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 0.348402\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 0.538430\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 0.443812\n",
      "Epoch: 10, Training Accuracy: 83.36%\n",
      "Epoch: 10, Validation Accuracy: 64.10%\n",
      "Epoch: 10, Testing Accuracy: 64.10%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 0.397080\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 0.297412\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 0.489044\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 0.633678\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 0.406432\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 0.419765\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 0.396715\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 0.701717\n",
      "Epoch: 11, Training Accuracy: 83.69%\n",
      "Epoch: 11, Validation Accuracy: 57.69%\n",
      "Epoch: 11, Testing Accuracy: 65.38%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 0.480775\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 0.373270\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 0.415097\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 0.425457\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 0.494499\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 0.404519\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 0.449713\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 0.311442\n",
      "Epoch: 12, Training Accuracy: 83.36%\n",
      "Epoch: 12, Validation Accuracy: 61.54%\n",
      "Epoch: 12, Testing Accuracy: 69.23%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 0.244400\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 0.297535\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 0.161228\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 0.455875\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 0.400561\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 0.331651\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 0.372656\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 0.152602\n",
      "Epoch: 13, Training Accuracy: 88.85%\n",
      "Epoch: 13, Validation Accuracy: 73.08%\n",
      "Epoch: 13, Testing Accuracy: 73.08%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 0.206673\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 0.330145\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 0.362251\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 0.177119\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 0.229379\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 0.501553\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 0.222453\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 0.182886\n",
      "Epoch: 14, Training Accuracy: 90.85%\n",
      "Epoch: 14, Validation Accuracy: 69.23%\n",
      "Epoch: 14, Testing Accuracy: 71.79%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 0.101756\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 0.260606\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 0.127332\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 0.342845\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 0.300958\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 0.139781\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 0.366440\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 0.266870\n",
      "Epoch: 15, Training Accuracy: 90.02%\n",
      "Epoch: 15, Validation Accuracy: 65.38%\n",
      "Epoch: 15, Testing Accuracy: 74.36%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 0.408621\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 0.332328\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 0.156203\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 0.270747\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 0.260943\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 0.212114\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 0.246481\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 0.909158\n",
      "Epoch: 16, Training Accuracy: 87.52%\n",
      "Epoch: 16, Validation Accuracy: 64.10%\n",
      "Epoch: 16, Testing Accuracy: 67.95%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 0.391064\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 0.186948\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 0.143897\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 0.213977\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 0.223769\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 0.186804\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 0.103488\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 0.303732\n",
      "Epoch: 17, Training Accuracy: 83.86%\n",
      "Epoch: 17, Validation Accuracy: 58.97%\n",
      "Epoch: 17, Testing Accuracy: 66.67%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 0.336887\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 0.289130\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 0.294463\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 0.166889\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 0.253233\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 0.164475\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 0.437469\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 0.161444\n",
      "Epoch: 18, Training Accuracy: 92.68%\n",
      "Epoch: 18, Validation Accuracy: 67.95%\n",
      "Epoch: 18, Testing Accuracy: 71.79%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 0.154127\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 0.205674\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 0.113721\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 0.368063\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 0.097533\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 0.188429\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 0.232801\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 0.209991\n",
      "Epoch: 19, Training Accuracy: 93.34%\n",
      "Epoch: 19, Validation Accuracy: 70.51%\n",
      "Epoch: 19, Testing Accuracy: 71.79%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 0.038466\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 0.211284\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 0.137371\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 0.095352\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 0.204847\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 0.171064\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 0.092909\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 0.172273\n",
      "Epoch: 20, Training Accuracy: 88.02%\n",
      "Epoch: 20, Validation Accuracy: 66.67%\n",
      "Epoch: 20, Testing Accuracy: 70.51%\n",
      "Training and evaluation finished in: 415.8005928993225 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 64.48, Recall: 64.29, F1-Score: 63.52\n",
      "Confusion Matrix:\n",
      "[[181  13 140   6]\n",
      " [  6 177  15 182]\n",
      " [ 49   6 356   9]\n",
      " [ 16  98  17 289]]\n",
      "Class 0 Accuracy: 53.24%\n",
      "Class 1 Accuracy: 46.58%\n",
      "Class 2 Accuracy: 84.76%\n",
      "Class 3 Accuracy: 68.81%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(image_size , 2)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)\n",
    "runModel(model, optimizer, None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11df9e85-82ae-4efd-ba66-aa0f85b1218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 3.292532\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.376858\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.404992\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.386560\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.425201\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 1.407784\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.355771\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 1.364277\n",
      "Epoch: 1, Training Accuracy: 29.28%\n",
      "Epoch: 1, Validation Accuracy: 28.21%\n",
      "Epoch: 1, Testing Accuracy: 32.05%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.394343\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.376668\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 1.369573\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.483323\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 1.385440\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 1.382094\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 1.317208\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 1.335960\n",
      "Epoch: 2, Training Accuracy: 29.28%\n",
      "Epoch: 2, Validation Accuracy: 28.21%\n",
      "Epoch: 2, Testing Accuracy: 32.05%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 1.410843\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 1.413864\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 1.418123\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 1.368312\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 1.363534\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 1.366796\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 1.406718\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 1.372566\n",
      "Epoch: 3, Training Accuracy: 26.79%\n",
      "Epoch: 3, Validation Accuracy: 25.64%\n",
      "Epoch: 3, Testing Accuracy: 26.92%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 1.381564\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 1.404447\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 1.390871\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 1.414960\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 1.370139\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 1.418026\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 1.373257\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 1.406130\n",
      "Epoch: 4, Training Accuracy: 27.45%\n",
      "Epoch: 4, Validation Accuracy: 25.64%\n",
      "Epoch: 4, Testing Accuracy: 26.92%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 1.348888\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 1.344187\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 1.391902\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 1.384372\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 1.366306\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 1.401082\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 1.370505\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 1.357520\n",
      "Epoch: 5, Training Accuracy: 28.79%\n",
      "Epoch: 5, Validation Accuracy: 28.21%\n",
      "Epoch: 5, Testing Accuracy: 26.92%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 1.378811\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 1.400619\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 1.381196\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 1.363657\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 1.385647\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 1.363961\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 1.377961\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 1.416080\n",
      "Epoch: 6, Training Accuracy: 26.79%\n",
      "Epoch: 6, Validation Accuracy: 25.64%\n",
      "Epoch: 6, Testing Accuracy: 26.92%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 1.384814\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 1.370574\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 1.335855\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 1.377869\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 1.397058\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 1.356451\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 1.401297\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 1.348356\n",
      "Epoch: 7, Training Accuracy: 28.95%\n",
      "Epoch: 7, Validation Accuracy: 28.21%\n",
      "Epoch: 7, Testing Accuracy: 26.92%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 1.373648\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 1.347407\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 1.375822\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 1.425596\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 1.377696\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 1.383106\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 1.358709\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 1.402088\n",
      "Epoch: 8, Training Accuracy: 44.26%\n",
      "Epoch: 8, Validation Accuracy: 38.46%\n",
      "Epoch: 8, Testing Accuracy: 43.59%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 1.365877\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 1.365270\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 1.455486\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 1.360115\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 1.399242\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 1.378898\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 1.399439\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 1.323364\n",
      "Epoch: 9, Training Accuracy: 29.45%\n",
      "Epoch: 9, Validation Accuracy: 28.21%\n",
      "Epoch: 9, Testing Accuracy: 30.77%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 1.349369\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 1.379391\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 1.346648\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 1.379927\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 1.388594\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 1.370178\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 1.383465\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 1.401643\n",
      "Epoch: 10, Training Accuracy: 32.45%\n",
      "Epoch: 10, Validation Accuracy: 30.77%\n",
      "Epoch: 10, Testing Accuracy: 37.18%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 1.335056\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 1.326551\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 1.381119\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 1.400749\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 1.388148\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 1.368938\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 1.373998\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 1.431746\n",
      "Epoch: 11, Training Accuracy: 41.76%\n",
      "Epoch: 11, Validation Accuracy: 35.90%\n",
      "Epoch: 11, Testing Accuracy: 43.59%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 1.362516\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 1.387425\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 1.359504\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 1.318727\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 1.371154\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 1.346239\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 1.338767\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 1.404452\n",
      "Epoch: 12, Training Accuracy: 26.79%\n",
      "Epoch: 12, Validation Accuracy: 25.64%\n",
      "Epoch: 12, Testing Accuracy: 26.92%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 1.379507\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 1.379472\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 1.357267\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 1.420238\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 1.344996\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 1.371695\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 1.355427\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 1.368319\n",
      "Epoch: 13, Training Accuracy: 30.28%\n",
      "Epoch: 13, Validation Accuracy: 28.21%\n",
      "Epoch: 13, Testing Accuracy: 32.05%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 1.284182\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 1.350075\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 1.372938\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 1.343173\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 1.334962\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 1.358379\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 1.380733\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 1.378603\n",
      "Epoch: 14, Training Accuracy: 26.79%\n",
      "Epoch: 14, Validation Accuracy: 25.64%\n",
      "Epoch: 14, Testing Accuracy: 26.92%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 1.291644\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 1.340541\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 1.385517\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 1.489565\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 1.339919\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 1.393405\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 1.326010\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 1.388750\n",
      "Epoch: 15, Training Accuracy: 30.12%\n",
      "Epoch: 15, Validation Accuracy: 28.21%\n",
      "Epoch: 15, Testing Accuracy: 30.77%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 1.377884\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 1.407510\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 1.301965\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 1.324297\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 1.328007\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 1.376018\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 1.369555\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 1.323857\n",
      "Epoch: 16, Training Accuracy: 45.92%\n",
      "Epoch: 16, Validation Accuracy: 42.31%\n",
      "Epoch: 16, Testing Accuracy: 47.44%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 1.340176\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 1.329741\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 1.327420\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 1.377385\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 1.350306\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 1.380727\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 1.385255\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 1.346875\n",
      "Epoch: 17, Training Accuracy: 26.79%\n",
      "Epoch: 17, Validation Accuracy: 25.64%\n",
      "Epoch: 17, Testing Accuracy: 26.92%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 1.324676\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 1.354817\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 1.345481\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 1.313322\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 1.336374\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 1.361924\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 1.311036\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 1.359388\n",
      "Epoch: 18, Training Accuracy: 39.10%\n",
      "Epoch: 18, Validation Accuracy: 34.62%\n",
      "Epoch: 18, Testing Accuracy: 41.03%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 1.369073\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 1.358088\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 1.371487\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 1.325901\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 1.333718\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 1.328112\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 1.437839\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 1.319127\n",
      "Epoch: 19, Training Accuracy: 42.26%\n",
      "Epoch: 19, Validation Accuracy: 35.90%\n",
      "Epoch: 19, Testing Accuracy: 43.59%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 1.305893\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 1.363142\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 1.340301\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 1.337073\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 1.427810\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 1.409652\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 1.442097\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 1.288575\n",
      "Epoch: 20, Training Accuracy: 34.78%\n",
      "Epoch: 20, Validation Accuracy: 32.05%\n",
      "Epoch: 20, Testing Accuracy: 39.74%\n",
      "Training and evaluation finished in: 340.9723196029663 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 18.09, Recall: 33.46, F1-Score: 23.26\n",
      "Confusion Matrix:\n",
      "[[  0   0 185 155]\n",
      " [  0   0 112 268]\n",
      " [  0   0 213 207]\n",
      " [  0   0 111 309]]\n",
      "Class 0 Accuracy: 0.00%\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 50.71%\n",
      "Class 3 Accuracy: 73.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u5588649\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "model = ConvNet(image_size , 3)\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)\n",
    "runModel(model, optimizer, None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "100e89ec-3329-4761-988e-432e215016fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 4.758243\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.125328\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.191504\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.542684\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.445540\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 1.198609\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.113742\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 1.120309\n",
      "Epoch: 1, Training Accuracy: 39.10%\n",
      "Epoch: 1, Validation Accuracy: 43.59%\n",
      "Epoch: 1, Testing Accuracy: 44.87%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.260209\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.106963\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 0.896620\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.403111\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 1.049507\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 1.077821\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 1.281857\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 0.829710\n",
      "Epoch: 2, Training Accuracy: 42.60%\n",
      "Epoch: 2, Validation Accuracy: 43.59%\n",
      "Epoch: 2, Testing Accuracy: 44.87%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 1.166939\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 1.036106\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 0.901042\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 1.043474\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 1.055776\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 1.048537\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 1.380446\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 0.945588\n",
      "Epoch: 3, Training Accuracy: 47.09%\n",
      "Epoch: 3, Validation Accuracy: 47.44%\n",
      "Epoch: 3, Testing Accuracy: 44.87%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 1.191129\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 0.961272\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 0.966888\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 0.947321\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 1.099358\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 1.254060\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 0.988745\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 1.063292\n",
      "Epoch: 4, Training Accuracy: 54.08%\n",
      "Epoch: 4, Validation Accuracy: 48.72%\n",
      "Epoch: 4, Testing Accuracy: 52.56%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 1.011939\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 1.096940\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 1.043375\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 1.161007\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 0.962450\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 0.960864\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 1.142410\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 1.118497\n",
      "Epoch: 5, Training Accuracy: 49.42%\n",
      "Epoch: 5, Validation Accuracy: 42.31%\n",
      "Epoch: 5, Testing Accuracy: 50.00%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 1.325684\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 1.282641\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 1.105648\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 0.983899\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 0.937819\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 1.196176\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 0.907048\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 1.194235\n",
      "Epoch: 6, Training Accuracy: 58.74%\n",
      "Epoch: 6, Validation Accuracy: 48.72%\n",
      "Epoch: 6, Testing Accuracy: 51.28%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 1.157699\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 1.067856\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 0.849383\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 0.829392\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 1.009878\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 1.348801\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 1.025265\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 0.901836\n",
      "Epoch: 7, Training Accuracy: 57.07%\n",
      "Epoch: 7, Validation Accuracy: 51.28%\n",
      "Epoch: 7, Testing Accuracy: 55.13%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 0.868691\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 0.869475\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 1.023196\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 0.954949\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 0.848875\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 0.968268\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 0.956841\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 1.054723\n",
      "Epoch: 8, Training Accuracy: 55.07%\n",
      "Epoch: 8, Validation Accuracy: 48.72%\n",
      "Epoch: 8, Testing Accuracy: 52.56%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 0.792721\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 0.794508\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 1.393343\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 1.070752\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 0.762421\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 1.294363\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 1.000289\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 0.996943\n",
      "Epoch: 9, Training Accuracy: 50.42%\n",
      "Epoch: 9, Validation Accuracy: 47.44%\n",
      "Epoch: 9, Testing Accuracy: 50.00%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 0.923842\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 0.741963\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 0.816997\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 0.807844\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 1.018050\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 1.135630\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 1.046141\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 1.067994\n",
      "Epoch: 10, Training Accuracy: 57.90%\n",
      "Epoch: 10, Validation Accuracy: 51.28%\n",
      "Epoch: 10, Testing Accuracy: 46.15%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 0.980138\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 0.950338\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 0.798236\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 0.790402\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 0.831198\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 0.852207\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 0.823267\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 0.960097\n",
      "Epoch: 11, Training Accuracy: 58.40%\n",
      "Epoch: 11, Validation Accuracy: 39.74%\n",
      "Epoch: 11, Testing Accuracy: 51.28%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 1.016194\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 0.800112\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 1.090098\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 0.740031\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 0.980790\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 0.758812\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 0.815561\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 1.111111\n",
      "Epoch: 12, Training Accuracy: 51.75%\n",
      "Epoch: 12, Validation Accuracy: 44.87%\n",
      "Epoch: 12, Testing Accuracy: 48.72%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 0.920740\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 0.844259\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 0.763282\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 1.116261\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 1.102320\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 0.739607\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 0.666261\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 1.125683\n",
      "Epoch: 13, Training Accuracy: 56.07%\n",
      "Epoch: 13, Validation Accuracy: 47.44%\n",
      "Epoch: 13, Testing Accuracy: 48.72%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 0.874859\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 0.702149\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 1.286478\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 0.724569\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 0.789114\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 0.775610\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 0.752923\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 0.808839\n",
      "Epoch: 14, Training Accuracy: 54.24%\n",
      "Epoch: 14, Validation Accuracy: 48.72%\n",
      "Epoch: 14, Testing Accuracy: 44.87%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 1.191886\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 0.661739\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 0.987505\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 0.712101\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 0.769259\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 0.769620\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 0.618698\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 1.027084\n",
      "Epoch: 15, Training Accuracy: 69.22%\n",
      "Epoch: 15, Validation Accuracy: 62.82%\n",
      "Epoch: 15, Testing Accuracy: 57.69%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 0.815067\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 0.670895\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 0.717215\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 0.885879\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 0.784947\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 0.983469\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 0.927316\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 0.748263\n",
      "Epoch: 16, Training Accuracy: 68.05%\n",
      "Epoch: 16, Validation Accuracy: 56.41%\n",
      "Epoch: 16, Testing Accuracy: 52.56%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 0.733791\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 0.591281\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 1.155113\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 1.076905\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 0.794011\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 0.636568\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 0.933951\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 0.678351\n",
      "Epoch: 17, Training Accuracy: 65.56%\n",
      "Epoch: 17, Validation Accuracy: 52.56%\n",
      "Epoch: 17, Testing Accuracy: 47.44%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 1.063702\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 0.976092\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 0.695758\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 0.751792\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 0.549867\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 0.650542\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 0.678140\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 0.605697\n",
      "Epoch: 18, Training Accuracy: 57.40%\n",
      "Epoch: 18, Validation Accuracy: 47.44%\n",
      "Epoch: 18, Testing Accuracy: 48.72%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 1.026448\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 0.605846\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 0.744779\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 0.635170\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 0.764079\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 0.528251\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 0.783104\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 0.794580\n",
      "Epoch: 19, Training Accuracy: 74.04%\n",
      "Epoch: 19, Validation Accuracy: 47.44%\n",
      "Epoch: 19, Testing Accuracy: 50.00%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 0.708822\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 0.867431\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 0.699145\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 0.562870\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 0.758280\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 0.642329\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 0.735302\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 0.886873\n",
      "Epoch: 20, Training Accuracy: 69.38%\n",
      "Epoch: 20, Validation Accuracy: 48.72%\n",
      "Epoch: 20, Testing Accuracy: 47.44%\n",
      "Training and evaluation finished in: 344.84514021873474 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 49.49, Recall: 49.49, F1-Score: 49.09\n",
      "Confusion Matrix:\n",
      "[[156  24 153   7]\n",
      " [ 37 132  26 185]\n",
      " [163  25 218  14]\n",
      " [ 29  87  38 266]]\n",
      "Class 0 Accuracy: 45.88%\n",
      "Class 1 Accuracy: 34.74%\n",
      "Class 2 Accuracy: 51.90%\n",
      "Class 3 Accuracy: 63.33%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "model = ConvNet(image_size , 4)\n",
    "optimizer = optim.SGD(params = model.parameters(), lr = learning_rate)\n",
    "runModel(model, optimizer, None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ad39d7e-d550-4fa1-8121-0528fe18531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 2.703585\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.214542\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.323028\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.286260\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.332494\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 0.945579\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.191540\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 0.891938\n",
      "Epoch: 1, Training Accuracy: 55.91%\n",
      "Epoch: 1, Validation Accuracy: 56.41%\n",
      "Epoch: 1, Testing Accuracy: 55.13%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.043403\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.068133\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 0.812672\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.106075\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 1.326671\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 1.003737\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 0.573176\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 0.598474\n",
      "Epoch: 2, Training Accuracy: 64.89%\n",
      "Epoch: 2, Validation Accuracy: 66.67%\n",
      "Epoch: 2, Testing Accuracy: 71.79%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 0.814861\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 0.677261\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 0.722636\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 0.701641\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 0.633787\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 0.623586\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 0.613748\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 0.437922\n",
      "Epoch: 3, Training Accuracy: 75.71%\n",
      "Epoch: 3, Validation Accuracy: 69.23%\n",
      "Epoch: 3, Testing Accuracy: 79.49%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 0.907294\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 0.535573\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 0.542051\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 0.743311\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 0.547289\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 0.438847\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 0.431414\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 0.432199\n",
      "Epoch: 4, Training Accuracy: 72.71%\n",
      "Epoch: 4, Validation Accuracy: 70.51%\n",
      "Epoch: 4, Testing Accuracy: 71.79%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 0.620073\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 0.478223\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 0.586723\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 0.294868\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 0.459717\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 0.386543\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 0.534797\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 0.346438\n",
      "Epoch: 5, Training Accuracy: 81.86%\n",
      "Epoch: 5, Validation Accuracy: 73.08%\n",
      "Epoch: 5, Testing Accuracy: 83.33%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 0.464199\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 0.509757\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 0.228915\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 0.175627\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 0.400823\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 0.332729\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 0.610301\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 0.435735\n",
      "Epoch: 6, Training Accuracy: 81.03%\n",
      "Epoch: 6, Validation Accuracy: 73.08%\n",
      "Epoch: 6, Testing Accuracy: 83.33%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 0.431462\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 0.264033\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 0.286451\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 0.379640\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 0.421575\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 0.369465\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 0.217587\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 0.235897\n",
      "Epoch: 7, Training Accuracy: 91.18%\n",
      "Epoch: 7, Validation Accuracy: 82.05%\n",
      "Epoch: 7, Testing Accuracy: 87.18%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 0.295321\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 0.253580\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 0.187457\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 0.230379\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 0.213257\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 0.429882\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 0.083274\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 0.268944\n",
      "Epoch: 8, Training Accuracy: 85.69%\n",
      "Epoch: 8, Validation Accuracy: 74.36%\n",
      "Epoch: 8, Testing Accuracy: 83.33%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 0.157277\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 0.241513\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 0.278420\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 0.280458\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 0.496026\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 0.448769\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 0.590269\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 0.270959\n",
      "Epoch: 9, Training Accuracy: 92.85%\n",
      "Epoch: 9, Validation Accuracy: 76.92%\n",
      "Epoch: 9, Testing Accuracy: 87.18%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 0.320408\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 0.070342\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 0.248798\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 0.342588\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 0.213417\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 0.143316\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 0.124079\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 0.170882\n",
      "Epoch: 10, Training Accuracy: 90.52%\n",
      "Epoch: 10, Validation Accuracy: 76.92%\n",
      "Epoch: 10, Testing Accuracy: 78.21%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 0.443194\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 0.192809\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 0.336982\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 0.315643\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 0.176265\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 0.104677\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 0.114116\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 0.247366\n",
      "Epoch: 11, Training Accuracy: 96.17%\n",
      "Epoch: 11, Validation Accuracy: 80.77%\n",
      "Epoch: 11, Testing Accuracy: 88.46%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 0.099983\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 0.084976\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 0.098402\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 0.137012\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 0.201550\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 0.186480\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 0.158229\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 0.059080\n",
      "Epoch: 12, Training Accuracy: 86.19%\n",
      "Epoch: 12, Validation Accuracy: 73.08%\n",
      "Epoch: 12, Testing Accuracy: 78.21%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 0.541774\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 0.158451\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 0.148308\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 0.126374\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 0.099527\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 0.086438\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 0.147487\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 0.158951\n",
      "Epoch: 13, Training Accuracy: 96.84%\n",
      "Epoch: 13, Validation Accuracy: 84.62%\n",
      "Epoch: 13, Testing Accuracy: 91.03%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 0.273008\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 0.107418\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 0.217167\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 0.029698\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 0.045948\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 0.261946\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 0.098863\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 0.014259\n",
      "Epoch: 14, Training Accuracy: 98.50%\n",
      "Epoch: 14, Validation Accuracy: 83.33%\n",
      "Epoch: 14, Testing Accuracy: 91.03%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 0.031011\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 0.081543\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 0.112094\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 0.164360\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 0.024577\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 0.052144\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 0.057328\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 0.100275\n",
      "Epoch: 15, Training Accuracy: 98.34%\n",
      "Epoch: 15, Validation Accuracy: 79.49%\n",
      "Epoch: 15, Testing Accuracy: 91.03%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 0.027555\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 0.152949\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 0.619974\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 0.126581\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 0.111336\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 0.058418\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 0.035837\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 0.050687\n",
      "Epoch: 16, Training Accuracy: 99.33%\n",
      "Epoch: 16, Validation Accuracy: 82.05%\n",
      "Epoch: 16, Testing Accuracy: 91.03%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 0.037999\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 0.014720\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 0.052876\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 0.062399\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 0.034461\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 0.013230\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 0.008184\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 0.096551\n",
      "Epoch: 17, Training Accuracy: 99.67%\n",
      "Epoch: 17, Validation Accuracy: 85.90%\n",
      "Epoch: 17, Testing Accuracy: 92.31%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 0.031931\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 0.084991\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 0.084450\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 0.006546\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 0.024593\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 0.032943\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 0.023885\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 0.010929\n",
      "Epoch: 18, Training Accuracy: 99.17%\n",
      "Epoch: 18, Validation Accuracy: 82.05%\n",
      "Epoch: 18, Testing Accuracy: 89.74%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 0.024637\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 0.002989\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 0.083448\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 0.028781\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 0.025273\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 0.004015\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 0.016596\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 0.007057\n",
      "Epoch: 19, Training Accuracy: 99.17%\n",
      "Epoch: 19, Validation Accuracy: 83.33%\n",
      "Epoch: 19, Testing Accuracy: 88.46%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 0.115594\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 0.006097\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 0.010913\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 0.001241\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 0.014902\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 0.009474\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 0.003430\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 0.035773\n",
      "Epoch: 20, Training Accuracy: 99.83%\n",
      "Epoch: 20, Validation Accuracy: 84.62%\n",
      "Epoch: 20, Testing Accuracy: 92.31%\n",
      "Training and evaluation finished in: 32.36476945877075 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 83.92, Recall: 83.72, F1-Score: 83.77\n",
      "Confusion Matrix:\n",
      "[[289  29   9  13]\n",
      " [ 17 288  14  61]\n",
      " [ 10   6 404   0]\n",
      " [  7  85   3 325]]\n",
      "Class 0 Accuracy: 85.00%\n",
      "Class 1 Accuracy: 75.79%\n",
      "Class 2 Accuracy: 96.19%\n",
      "Class 3 Accuracy: 77.38%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(image_size , 1)\n",
    "lr_ADAMb = 0.001\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = lr_ADAMb)\n",
    "runModel(model, optimizer, None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "517a4118-e6c8-4867-b2d9-504ff14e3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/601 (0%)]\tLoss: 2.703585\n",
      "Train Epoch: 1 [80/601 (13%)]\tLoss: 1.214542\n",
      "Train Epoch: 1 [160/601 (26%)]\tLoss: 1.323028\n",
      "Train Epoch: 1 [240/601 (39%)]\tLoss: 1.286260\n",
      "Train Epoch: 1 [320/601 (53%)]\tLoss: 1.332494\n",
      "Train Epoch: 1 [400/601 (66%)]\tLoss: 0.945579\n",
      "Train Epoch: 1 [480/601 (79%)]\tLoss: 1.191540\n",
      "Train Epoch: 1 [560/601 (92%)]\tLoss: 0.891938\n",
      "Epoch: 1, Training Accuracy: 55.91%\n",
      "Epoch: 1, Validation Accuracy: 56.41%\n",
      "Epoch: 1, Testing Accuracy: 55.13%\n",
      "Train Epoch: 2 [0/601 (0%)]\tLoss: 1.043403\n",
      "Train Epoch: 2 [80/601 (13%)]\tLoss: 1.068133\n",
      "Train Epoch: 2 [160/601 (26%)]\tLoss: 0.812672\n",
      "Train Epoch: 2 [240/601 (39%)]\tLoss: 1.106075\n",
      "Train Epoch: 2 [320/601 (53%)]\tLoss: 1.326671\n",
      "Train Epoch: 2 [400/601 (66%)]\tLoss: 1.003737\n",
      "Train Epoch: 2 [480/601 (79%)]\tLoss: 0.573176\n",
      "Train Epoch: 2 [560/601 (92%)]\tLoss: 0.598474\n",
      "Epoch: 2, Training Accuracy: 64.89%\n",
      "Epoch: 2, Validation Accuracy: 66.67%\n",
      "Epoch: 2, Testing Accuracy: 71.79%\n",
      "Train Epoch: 3 [0/601 (0%)]\tLoss: 0.814861\n",
      "Train Epoch: 3 [80/601 (13%)]\tLoss: 0.677261\n",
      "Train Epoch: 3 [160/601 (26%)]\tLoss: 0.722636\n",
      "Train Epoch: 3 [240/601 (39%)]\tLoss: 0.701641\n",
      "Train Epoch: 3 [320/601 (53%)]\tLoss: 0.633787\n",
      "Train Epoch: 3 [400/601 (66%)]\tLoss: 0.623586\n",
      "Train Epoch: 3 [480/601 (79%)]\tLoss: 0.613748\n",
      "Train Epoch: 3 [560/601 (92%)]\tLoss: 0.437922\n",
      "Epoch: 3, Training Accuracy: 75.71%\n",
      "Epoch: 3, Validation Accuracy: 69.23%\n",
      "Epoch: 3, Testing Accuracy: 79.49%\n",
      "Train Epoch: 4 [0/601 (0%)]\tLoss: 0.907294\n",
      "Train Epoch: 4 [80/601 (13%)]\tLoss: 0.535573\n",
      "Train Epoch: 4 [160/601 (26%)]\tLoss: 0.542051\n",
      "Train Epoch: 4 [240/601 (39%)]\tLoss: 0.743311\n",
      "Train Epoch: 4 [320/601 (53%)]\tLoss: 0.547289\n",
      "Train Epoch: 4 [400/601 (66%)]\tLoss: 0.438847\n",
      "Train Epoch: 4 [480/601 (79%)]\tLoss: 0.431414\n",
      "Train Epoch: 4 [560/601 (92%)]\tLoss: 0.432199\n",
      "Epoch: 4, Training Accuracy: 72.71%\n",
      "Epoch: 4, Validation Accuracy: 70.51%\n",
      "Epoch: 4, Testing Accuracy: 71.79%\n",
      "Train Epoch: 5 [0/601 (0%)]\tLoss: 0.620073\n",
      "Train Epoch: 5 [80/601 (13%)]\tLoss: 0.478223\n",
      "Train Epoch: 5 [160/601 (26%)]\tLoss: 0.586723\n",
      "Train Epoch: 5 [240/601 (39%)]\tLoss: 0.294868\n",
      "Train Epoch: 5 [320/601 (53%)]\tLoss: 0.459717\n",
      "Train Epoch: 5 [400/601 (66%)]\tLoss: 0.386543\n",
      "Train Epoch: 5 [480/601 (79%)]\tLoss: 0.534797\n",
      "Train Epoch: 5 [560/601 (92%)]\tLoss: 0.346438\n",
      "Epoch: 5, Training Accuracy: 81.86%\n",
      "Epoch: 5, Validation Accuracy: 73.08%\n",
      "Epoch: 5, Testing Accuracy: 83.33%\n",
      "Train Epoch: 6 [0/601 (0%)]\tLoss: 0.464199\n",
      "Train Epoch: 6 [80/601 (13%)]\tLoss: 0.509757\n",
      "Train Epoch: 6 [160/601 (26%)]\tLoss: 0.228915\n",
      "Train Epoch: 6 [240/601 (39%)]\tLoss: 0.175627\n",
      "Train Epoch: 6 [320/601 (53%)]\tLoss: 0.400823\n",
      "Train Epoch: 6 [400/601 (66%)]\tLoss: 0.332729\n",
      "Train Epoch: 6 [480/601 (79%)]\tLoss: 0.610301\n",
      "Train Epoch: 6 [560/601 (92%)]\tLoss: 0.435735\n",
      "Epoch: 6, Training Accuracy: 81.03%\n",
      "Epoch: 6, Validation Accuracy: 73.08%\n",
      "Epoch: 6, Testing Accuracy: 83.33%\n",
      "Train Epoch: 7 [0/601 (0%)]\tLoss: 0.431462\n",
      "Train Epoch: 7 [80/601 (13%)]\tLoss: 0.264033\n",
      "Train Epoch: 7 [160/601 (26%)]\tLoss: 0.286451\n",
      "Train Epoch: 7 [240/601 (39%)]\tLoss: 0.379640\n",
      "Train Epoch: 7 [320/601 (53%)]\tLoss: 0.421575\n",
      "Train Epoch: 7 [400/601 (66%)]\tLoss: 0.369465\n",
      "Train Epoch: 7 [480/601 (79%)]\tLoss: 0.217587\n",
      "Train Epoch: 7 [560/601 (92%)]\tLoss: 0.235897\n",
      "Epoch: 7, Training Accuracy: 91.18%\n",
      "Epoch: 7, Validation Accuracy: 82.05%\n",
      "Epoch: 7, Testing Accuracy: 87.18%\n",
      "Train Epoch: 8 [0/601 (0%)]\tLoss: 0.295321\n",
      "Train Epoch: 8 [80/601 (13%)]\tLoss: 0.253580\n",
      "Train Epoch: 8 [160/601 (26%)]\tLoss: 0.187457\n",
      "Train Epoch: 8 [240/601 (39%)]\tLoss: 0.230379\n",
      "Train Epoch: 8 [320/601 (53%)]\tLoss: 0.213257\n",
      "Train Epoch: 8 [400/601 (66%)]\tLoss: 0.429882\n",
      "Train Epoch: 8 [480/601 (79%)]\tLoss: 0.083274\n",
      "Train Epoch: 8 [560/601 (92%)]\tLoss: 0.268944\n",
      "Epoch: 8, Training Accuracy: 85.69%\n",
      "Epoch: 8, Validation Accuracy: 74.36%\n",
      "Epoch: 8, Testing Accuracy: 83.33%\n",
      "Train Epoch: 9 [0/601 (0%)]\tLoss: 0.157277\n",
      "Train Epoch: 9 [80/601 (13%)]\tLoss: 0.241513\n",
      "Train Epoch: 9 [160/601 (26%)]\tLoss: 0.278420\n",
      "Train Epoch: 9 [240/601 (39%)]\tLoss: 0.280458\n",
      "Train Epoch: 9 [320/601 (53%)]\tLoss: 0.496026\n",
      "Train Epoch: 9 [400/601 (66%)]\tLoss: 0.448769\n",
      "Train Epoch: 9 [480/601 (79%)]\tLoss: 0.590269\n",
      "Train Epoch: 9 [560/601 (92%)]\tLoss: 0.270959\n",
      "Epoch: 9, Training Accuracy: 92.85%\n",
      "Epoch: 9, Validation Accuracy: 76.92%\n",
      "Epoch: 9, Testing Accuracy: 87.18%\n",
      "Train Epoch: 10 [0/601 (0%)]\tLoss: 0.320408\n",
      "Train Epoch: 10 [80/601 (13%)]\tLoss: 0.070342\n",
      "Train Epoch: 10 [160/601 (26%)]\tLoss: 0.248798\n",
      "Train Epoch: 10 [240/601 (39%)]\tLoss: 0.342588\n",
      "Train Epoch: 10 [320/601 (53%)]\tLoss: 0.213417\n",
      "Train Epoch: 10 [400/601 (66%)]\tLoss: 0.143316\n",
      "Train Epoch: 10 [480/601 (79%)]\tLoss: 0.124079\n",
      "Train Epoch: 10 [560/601 (92%)]\tLoss: 0.170882\n",
      "Epoch: 10, Training Accuracy: 90.52%\n",
      "Epoch: 10, Validation Accuracy: 76.92%\n",
      "Epoch: 10, Testing Accuracy: 78.21%\n",
      "Train Epoch: 11 [0/601 (0%)]\tLoss: 0.443194\n",
      "Train Epoch: 11 [80/601 (13%)]\tLoss: 0.192809\n",
      "Train Epoch: 11 [160/601 (26%)]\tLoss: 0.336982\n",
      "Train Epoch: 11 [240/601 (39%)]\tLoss: 0.315643\n",
      "Train Epoch: 11 [320/601 (53%)]\tLoss: 0.176265\n",
      "Train Epoch: 11 [400/601 (66%)]\tLoss: 0.104677\n",
      "Train Epoch: 11 [480/601 (79%)]\tLoss: 0.114116\n",
      "Train Epoch: 11 [560/601 (92%)]\tLoss: 0.247366\n",
      "Epoch: 11, Training Accuracy: 96.17%\n",
      "Epoch: 11, Validation Accuracy: 80.77%\n",
      "Epoch: 11, Testing Accuracy: 88.46%\n",
      "Train Epoch: 12 [0/601 (0%)]\tLoss: 0.099983\n",
      "Train Epoch: 12 [80/601 (13%)]\tLoss: 0.084976\n",
      "Train Epoch: 12 [160/601 (26%)]\tLoss: 0.098402\n",
      "Train Epoch: 12 [240/601 (39%)]\tLoss: 0.137012\n",
      "Train Epoch: 12 [320/601 (53%)]\tLoss: 0.201550\n",
      "Train Epoch: 12 [400/601 (66%)]\tLoss: 0.186480\n",
      "Train Epoch: 12 [480/601 (79%)]\tLoss: 0.158229\n",
      "Train Epoch: 12 [560/601 (92%)]\tLoss: 0.059080\n",
      "Epoch: 12, Training Accuracy: 86.19%\n",
      "Epoch: 12, Validation Accuracy: 73.08%\n",
      "Epoch: 12, Testing Accuracy: 78.21%\n",
      "Train Epoch: 13 [0/601 (0%)]\tLoss: 0.541774\n",
      "Train Epoch: 13 [80/601 (13%)]\tLoss: 0.158451\n",
      "Train Epoch: 13 [160/601 (26%)]\tLoss: 0.148308\n",
      "Train Epoch: 13 [240/601 (39%)]\tLoss: 0.126374\n",
      "Train Epoch: 13 [320/601 (53%)]\tLoss: 0.099527\n",
      "Train Epoch: 13 [400/601 (66%)]\tLoss: 0.086438\n",
      "Train Epoch: 13 [480/601 (79%)]\tLoss: 0.147487\n",
      "Train Epoch: 13 [560/601 (92%)]\tLoss: 0.158951\n",
      "Epoch: 13, Training Accuracy: 96.84%\n",
      "Epoch: 13, Validation Accuracy: 84.62%\n",
      "Epoch: 13, Testing Accuracy: 91.03%\n",
      "Train Epoch: 14 [0/601 (0%)]\tLoss: 0.273008\n",
      "Train Epoch: 14 [80/601 (13%)]\tLoss: 0.107418\n",
      "Train Epoch: 14 [160/601 (26%)]\tLoss: 0.217167\n",
      "Train Epoch: 14 [240/601 (39%)]\tLoss: 0.029698\n",
      "Train Epoch: 14 [320/601 (53%)]\tLoss: 0.045948\n",
      "Train Epoch: 14 [400/601 (66%)]\tLoss: 0.261946\n",
      "Train Epoch: 14 [480/601 (79%)]\tLoss: 0.098863\n",
      "Train Epoch: 14 [560/601 (92%)]\tLoss: 0.014259\n",
      "Epoch: 14, Training Accuracy: 98.50%\n",
      "Epoch: 14, Validation Accuracy: 83.33%\n",
      "Epoch: 14, Testing Accuracy: 91.03%\n",
      "Train Epoch: 15 [0/601 (0%)]\tLoss: 0.031011\n",
      "Train Epoch: 15 [80/601 (13%)]\tLoss: 0.081543\n",
      "Train Epoch: 15 [160/601 (26%)]\tLoss: 0.112094\n",
      "Train Epoch: 15 [240/601 (39%)]\tLoss: 0.164360\n",
      "Train Epoch: 15 [320/601 (53%)]\tLoss: 0.024577\n",
      "Train Epoch: 15 [400/601 (66%)]\tLoss: 0.052144\n",
      "Train Epoch: 15 [480/601 (79%)]\tLoss: 0.057328\n",
      "Train Epoch: 15 [560/601 (92%)]\tLoss: 0.100275\n",
      "Epoch: 15, Training Accuracy: 98.34%\n",
      "Epoch: 15, Validation Accuracy: 79.49%\n",
      "Epoch: 15, Testing Accuracy: 91.03%\n",
      "Train Epoch: 16 [0/601 (0%)]\tLoss: 0.027555\n",
      "Train Epoch: 16 [80/601 (13%)]\tLoss: 0.152949\n",
      "Train Epoch: 16 [160/601 (26%)]\tLoss: 0.619974\n",
      "Train Epoch: 16 [240/601 (39%)]\tLoss: 0.126581\n",
      "Train Epoch: 16 [320/601 (53%)]\tLoss: 0.111336\n",
      "Train Epoch: 16 [400/601 (66%)]\tLoss: 0.058418\n",
      "Train Epoch: 16 [480/601 (79%)]\tLoss: 0.035837\n",
      "Train Epoch: 16 [560/601 (92%)]\tLoss: 0.050687\n",
      "Epoch: 16, Training Accuracy: 99.33%\n",
      "Epoch: 16, Validation Accuracy: 82.05%\n",
      "Epoch: 16, Testing Accuracy: 91.03%\n",
      "Train Epoch: 17 [0/601 (0%)]\tLoss: 0.037999\n",
      "Train Epoch: 17 [80/601 (13%)]\tLoss: 0.014720\n",
      "Train Epoch: 17 [160/601 (26%)]\tLoss: 0.052876\n",
      "Train Epoch: 17 [240/601 (39%)]\tLoss: 0.062399\n",
      "Train Epoch: 17 [320/601 (53%)]\tLoss: 0.034461\n",
      "Train Epoch: 17 [400/601 (66%)]\tLoss: 0.013230\n",
      "Train Epoch: 17 [480/601 (79%)]\tLoss: 0.008184\n",
      "Train Epoch: 17 [560/601 (92%)]\tLoss: 0.096551\n",
      "Epoch: 17, Training Accuracy: 99.67%\n",
      "Epoch: 17, Validation Accuracy: 85.90%\n",
      "Epoch: 17, Testing Accuracy: 92.31%\n",
      "Train Epoch: 18 [0/601 (0%)]\tLoss: 0.031931\n",
      "Train Epoch: 18 [80/601 (13%)]\tLoss: 0.084991\n",
      "Train Epoch: 18 [160/601 (26%)]\tLoss: 0.084450\n",
      "Train Epoch: 18 [240/601 (39%)]\tLoss: 0.006546\n",
      "Train Epoch: 18 [320/601 (53%)]\tLoss: 0.024593\n",
      "Train Epoch: 18 [400/601 (66%)]\tLoss: 0.032943\n",
      "Train Epoch: 18 [480/601 (79%)]\tLoss: 0.023885\n",
      "Train Epoch: 18 [560/601 (92%)]\tLoss: 0.010929\n",
      "Epoch: 18, Training Accuracy: 99.17%\n",
      "Epoch: 18, Validation Accuracy: 82.05%\n",
      "Epoch: 18, Testing Accuracy: 89.74%\n",
      "Train Epoch: 19 [0/601 (0%)]\tLoss: 0.024637\n",
      "Train Epoch: 19 [80/601 (13%)]\tLoss: 0.002989\n",
      "Train Epoch: 19 [160/601 (26%)]\tLoss: 0.083448\n",
      "Train Epoch: 19 [240/601 (39%)]\tLoss: 0.028781\n",
      "Train Epoch: 19 [320/601 (53%)]\tLoss: 0.025273\n",
      "Train Epoch: 19 [400/601 (66%)]\tLoss: 0.004015\n",
      "Train Epoch: 19 [480/601 (79%)]\tLoss: 0.016596\n",
      "Train Epoch: 19 [560/601 (92%)]\tLoss: 0.007057\n",
      "Epoch: 19, Training Accuracy: 99.17%\n",
      "Epoch: 19, Validation Accuracy: 83.33%\n",
      "Epoch: 19, Testing Accuracy: 88.46%\n",
      "Train Epoch: 20 [0/601 (0%)]\tLoss: 0.115594\n",
      "Train Epoch: 20 [80/601 (13%)]\tLoss: 0.006097\n",
      "Train Epoch: 20 [160/601 (26%)]\tLoss: 0.010913\n",
      "Train Epoch: 20 [240/601 (39%)]\tLoss: 0.001241\n",
      "Train Epoch: 20 [320/601 (53%)]\tLoss: 0.014902\n",
      "Train Epoch: 20 [400/601 (66%)]\tLoss: 0.009474\n",
      "Train Epoch: 20 [480/601 (79%)]\tLoss: 0.003430\n",
      "Train Epoch: 20 [560/601 (92%)]\tLoss: 0.035773\n",
      "Epoch: 20, Training Accuracy: 99.83%\n",
      "Epoch: 20, Validation Accuracy: 84.62%\n",
      "Epoch: 20, Testing Accuracy: 92.31%\n",
      "Training and evaluation finished in: 32.53931474685669 sec.\n",
      "Final Evaluation Metrics:\n",
      "Precision: 83.92, Recall: 83.72, F1-Score: 83.77\n",
      "Confusion Matrix:\n",
      "[[289  29   9  13]\n",
      " [ 17 288  14  61]\n",
      " [ 10   6 404   0]\n",
      " [  7  85   3 325]]\n",
      "Class 0 Accuracy: 85.00%\n",
      "Class 1 Accuracy: 75.79%\n",
      "Class 2 Accuracy: 96.19%\n",
      "Class 3 Accuracy: 77.38%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(image_size , 1)\n",
    "lr_ADAMb = 0.001\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = lr_ADAMb)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "runModel(model, optimizer, scheduler )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50447671-bfe3-4645-8d4a-e472f554ab78",
   "metadata": {},
   "source": [
    "### 2.2\tImproving performance through data augmentation (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ab42e6c-6d8f-46ef-a3be-dff6e308c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available() and cuda:\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    FloatType = torch.cuda.FloatTensor\n",
    "    LongType = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatType = torch.FloatTensor\n",
    "    LongType = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76b35ed7-79e9-44f4-b13c-74790ab54ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "image_size = 32*32\n",
    "num_classes = 62\n",
    "num_hidden_unit = 100\n",
    "\n",
    "# Training Hyperparameters (Note: These values are not the optimal ones)\n",
    "batch_size = 32 \n",
    "learning_rate = 0.1\n",
    "itr = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2178523b-f993-4bfd-894f-6e68fd2aed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation\n",
    "transforms = None\n",
    "augment = True\n",
    "\n",
    "transforms_regular = trans.Compose([trans.Grayscale(), trans.Resize([32,32]), trans.ToTensor(), trans.Normalize(mean=(0.5,), std = (0.5,))])\n",
    "\n",
    "data_augmentation = trans.Compose([trans.Grayscale(),\n",
    "    trans.RandomRotation(50),  # Rotate first to prevent cropping issues\n",
    "    trans.RandomResizedCrop(32, scale=(0.6, 1.2)),  # Then randomly crop & resize\n",
    "    trans.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.7, 1.3)),  # Shift & scale\n",
    "    trans.RandomPerspective(distortion_scale=0.2, p=0.5),  # Perspective distortions\n",
    "    trans.RandomHorizontalFlip(0.6),  # Flip signs if applicable\n",
    "    trans.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Blur to simulate low-quality images\n",
    "    trans.ColorJitter(brightness=0.3, contrast=0.3),  # Adjust brightness/contrast\n",
    "    trans.ToTensor(), trans.Normalize(mean=(0.5,), std = (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "if augment is True :\n",
    "    transforms = data_augmentation\n",
    "else:\n",
    "    transforms = transforms_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc035664-a6ba-47f9-9ac3-437f6c869c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "class BelgiumTSCDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.paths = glob(os.path.join(self.root, '**', \"*.png\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = self.transform(Image.open(path))\n",
    "        label = int(path.split(os.path.sep)[-2])\n",
    "        return img, label\n",
    "    \n",
    "train_data = BelgiumTSCDataset(root='./data/BelgiumTSC_Training/Training', transform= transforms)\n",
    "test_data = BelgiumTSCDataset(root='./data/BelgiumTSC_Testing/Testing', transform= transforms)\n",
    "\n",
    "subtest_data = BelgiumTSCDataset(root='./data/Test_subset', transform= transforms_regular)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False, num_workers = 0)\n",
    "subtest_loader = torch.utils.data.DataLoader(subtest_data, batch_size = batch_size, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "21ecc309-51ba-4eef-8672-000e367002b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.normal_(mean=0,std=1e-2)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.normal_(mean=0,std=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3382f718-0af6-4c10-83e0-3ba1ed17e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(model, optimizer, train_loader, loss_func, epoch, vis_step = 20):\n",
    "    # Number of samples with correct classification\n",
    "    num_hit = 0\n",
    "    # total size of train data\n",
    "    total = len(train_loader.dataset)\n",
    "    # Training loop over batches of data on train dataset\n",
    "    for batch_idx, (image, labels) in enumerate(train_loader):\n",
    "        # 1. Clearing previous gradient values.\n",
    "        optimizer.zero_grad()\n",
    "        # 2. feeding images to model (forward method will be computed)\n",
    "        output = model(image)\n",
    "        # 3. Calculating the loss value\n",
    "        loss = loss_func(output, labels)\n",
    "        # 4. Calculating new grdients given the loss value\n",
    "        loss.backward()\n",
    "        # 5. Updating the weights\n",
    "        optimizer.step()\n",
    "        # 6. logging (Optional)\n",
    "        if batch_idx % vis_step == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(image),\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss.data.item()))\n",
    "    # Validation Phase on train dataset\n",
    "    for batch_idx, (image, labels) in enumerate(train_loader):\n",
    "        output = model(image)\n",
    "        _ , pred_label = output.data.max(dim=1)\n",
    "        num_hit += (pred_label == labels.data).sum()\n",
    "    train_accuracy = (num_hit.item() / total)\n",
    "    print(\"Epoch: {}, Training Accuracy: {:.2f}%\".format(epoch, 100. * train_accuracy))\n",
    "    return 100. * train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c5c6070-5439-4d4f-adee-65e9556ebd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, epoch, name):\n",
    "    num_hit = 0\n",
    "    total = len(test_loader.dataset)\n",
    "    for batch_idx, (image, labels) in enumerate(test_loader): # Complete the rest of this function\n",
    "        output = model(image)\n",
    "        _ , pred_label = output.data.max(dim=1)\n",
    "        num_hit += (pred_label == labels.data).sum()\n",
    "    test_accuracy = (num_hit.item() / total)\n",
    "    print(\"Epoch: {}, {}Testing Accuracy: {:.2f}%\".format(epoch,name, 100. * test_accuracy))\n",
    "    return 100. * test_accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "692f1ef4-c9d5-44eb-bae7-40a74ca204d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetNew(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetNew, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "        \t                   out_channels=6,\n",
    "            \t\t\t\t   kernel_size=(3,3),\n",
    "            \t\t\t\t   stride=(1,1))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=6,\n",
    "                               out_channels=31,\n",
    "                               kernel_size=(2,2),\n",
    "                               stride=(1,1))# Complete this line\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size = (2,2)) # Complete this line\n",
    "        self.conv5 = nn.Conv2d(in_channels=31,\n",
    "                               out_channels=93,\n",
    "                               kernel_size=(2,2),\n",
    "                               stride=(1,1)) # Complete this line\n",
    "        self.pool6 = nn.MaxPool2d(kernel_size = (2,2)) # Complete this line\n",
    "        self.conv7 = nn.Conv2d(in_channels=93,\n",
    "                               out_channels=186,\n",
    "                               kernel_size=(3,3),\n",
    "                               stride=(1,1)) # Complete this line\n",
    "        self.fc8 = nn.Linear(in_features=186,\n",
    "            \t\t\t     out_features=124)\n",
    "        self.fc9 = nn.Linear(in_features=124,\n",
    "            \t\t\t     out_features=93)\n",
    "        self.fc10 = nn.Linear(in_features=93,\n",
    "                             out_features=62) # Complete this line\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view([-1, 1, 32, 32])\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool2(x)\n",
    "#         print(x.shape)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool4(x)\n",
    "#         print(x.shape)\n",
    "        x = nn.functional.relu(self.conv5(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool6(x)\n",
    "#         print(x.shape)\n",
    "        x = nn.functional.relu(self.conv7(x))\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 186)\n",
    "#         print(x.shape)\n",
    "        x = nn.functional.relu(self.fc8(x))\n",
    "#         print(x.shape)\n",
    "        x = nn.functional.relu(self.fc9(x))\n",
    "#         print(x.shape)\n",
    "        x = self.fc10(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c47eb9ce-1efc-4083-a927-721736e322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAugTest():\n",
    "    torch.manual_seed(0)\n",
    "    # 1. Instantiate from the model class \n",
    "    model = ConvNetNew(\n",
    "                     )\n",
    "    \n",
    "    # for running on gpu\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # 2. Initialize model's weight\n",
    "    model.apply(weights_init)\n",
    "    \n",
    "    # 3. Define optimizer and loss function\n",
    "    lr_ADAMb = 0.001\n",
    "    optimizer = optim.Adam(params = model.parameters(), lr = lr_ADAMb)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "     # 4. Write the training loop\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    subtest_acc = []\n",
    "    total_time = 0\n",
    "    for epoch in range(itr):\n",
    "        start = time()\n",
    "        tr_acc = train_model2(model, optimizer, train_loader, loss_func, epoch+1)\n",
    "        ts_acc = eval_model(model, test_loader, epoch+1, '')\n",
    "        subts_acc = eval_model(model, subtest_loader, epoch+1, 'Sub-')\n",
    "        train_acc.append(tr_acc)\n",
    "        test_acc.append(ts_acc)\n",
    "        subtest_acc.append(subts_acc)\n",
    "        end = time()\n",
    "        total_time += end-start\n",
    "    print(\"Training and evaluation finished in:\", total_time, \"sec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35011647-2be8-4b74-82d8-58aacea25822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e2b9414-d2da-4c97-a6b5-fc842d6b093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4575\n",
      "Train Epoch: 1 [0/4575 (0%)]\tLoss: 5.583474\n",
      "Train Epoch: 1 [640/4575 (14%)]\tLoss: 3.971108\n",
      "Train Epoch: 1 [1280/4575 (28%)]\tLoss: 3.235387\n",
      "Train Epoch: 1 [1920/4575 (42%)]\tLoss: 3.506693\n",
      "Train Epoch: 1 [2560/4575 (56%)]\tLoss: 2.212386\n",
      "Train Epoch: 1 [3200/4575 (70%)]\tLoss: 2.070684\n",
      "Train Epoch: 1 [3840/4575 (84%)]\tLoss: 1.980191\n",
      "Train Epoch: 1 [4480/4575 (98%)]\tLoss: 1.938052\n",
      "Epoch: 1, Training Accuracy: 59.17%\n",
      "Epoch: 1, Testing Accuracy: 56.55%\n",
      "Epoch: 1, Sub-Testing Accuracy: 3.19%\n",
      "4575\n",
      "Train Epoch: 2 [0/4575 (0%)]\tLoss: 1.474632\n",
      "Train Epoch: 2 [640/4575 (14%)]\tLoss: 1.920446\n",
      "Train Epoch: 2 [1280/4575 (28%)]\tLoss: 1.059073\n",
      "Train Epoch: 2 [1920/4575 (42%)]\tLoss: 1.443858\n",
      "Train Epoch: 2 [2560/4575 (56%)]\tLoss: 1.273787\n",
      "Train Epoch: 2 [3200/4575 (70%)]\tLoss: 1.068045\n",
      "Train Epoch: 2 [3840/4575 (84%)]\tLoss: 0.769453\n",
      "Train Epoch: 2 [4480/4575 (98%)]\tLoss: 1.025923\n",
      "Epoch: 2, Training Accuracy: 74.69%\n",
      "Epoch: 2, Testing Accuracy: 71.55%\n",
      "Epoch: 2, Sub-Testing Accuracy: 1.20%\n",
      "4575\n",
      "Train Epoch: 3 [0/4575 (0%)]\tLoss: 1.612582\n",
      "Train Epoch: 3 [640/4575 (14%)]\tLoss: 0.819457\n",
      "Train Epoch: 3 [1280/4575 (28%)]\tLoss: 0.831424\n",
      "Train Epoch: 3 [1920/4575 (42%)]\tLoss: 0.618280\n",
      "Train Epoch: 3 [2560/4575 (56%)]\tLoss: 0.333431\n",
      "Train Epoch: 3 [3200/4575 (70%)]\tLoss: 0.843461\n",
      "Train Epoch: 3 [3840/4575 (84%)]\tLoss: 0.697324\n",
      "Train Epoch: 3 [4480/4575 (98%)]\tLoss: 0.644570\n",
      "Epoch: 3, Training Accuracy: 85.88%\n",
      "Epoch: 3, Testing Accuracy: 79.92%\n",
      "Epoch: 3, Sub-Testing Accuracy: 3.19%\n",
      "4575\n",
      "Train Epoch: 4 [0/4575 (0%)]\tLoss: 0.609001\n",
      "Train Epoch: 4 [640/4575 (14%)]\tLoss: 0.505060\n",
      "Train Epoch: 4 [1280/4575 (28%)]\tLoss: 0.366902\n",
      "Train Epoch: 4 [1920/4575 (42%)]\tLoss: 0.643723\n",
      "Train Epoch: 4 [2560/4575 (56%)]\tLoss: 0.421293\n",
      "Train Epoch: 4 [3200/4575 (70%)]\tLoss: 0.106210\n",
      "Train Epoch: 4 [3840/4575 (84%)]\tLoss: 0.348785\n",
      "Train Epoch: 4 [4480/4575 (98%)]\tLoss: 0.459030\n",
      "Epoch: 4, Training Accuracy: 91.21%\n",
      "Epoch: 4, Testing Accuracy: 84.96%\n",
      "Epoch: 4, Sub-Testing Accuracy: 3.19%\n",
      "Training and evaluation finished in: 59.76370143890381 sec.\n"
     ]
    }
   ],
   "source": [
    "dataAugTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "64159121-2d6a-4277-a2a0-c6a95f78b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4575 (0%)]\tLoss: 6.198489\n",
      "Train Epoch: 1 [640/4575 (14%)]\tLoss: 3.948425\n",
      "Train Epoch: 1 [1280/4575 (28%)]\tLoss: 3.636053\n",
      "Train Epoch: 1 [1920/4575 (42%)]\tLoss: 3.857497\n",
      "Train Epoch: 1 [2560/4575 (56%)]\tLoss: 3.284226\n",
      "Train Epoch: 1 [3200/4575 (70%)]\tLoss: 3.633670\n",
      "Train Epoch: 1 [3840/4575 (84%)]\tLoss: 3.504374\n",
      "Train Epoch: 1 [4480/4575 (98%)]\tLoss: 3.536265\n",
      "Epoch: 1, Training Accuracy: 9.86%\n",
      "Epoch: 1, Testing Accuracy: 7.34%\n",
      "Epoch: 1, Sub-Testing Accuracy: 4.78%\n",
      "Train Epoch: 2 [0/4575 (0%)]\tLoss: 3.336920\n",
      "Train Epoch: 2 [640/4575 (14%)]\tLoss: 3.338401\n",
      "Train Epoch: 2 [1280/4575 (28%)]\tLoss: 3.614360\n",
      "Train Epoch: 2 [1920/4575 (42%)]\tLoss: 3.432230\n",
      "Train Epoch: 2 [2560/4575 (56%)]\tLoss: 3.368360\n",
      "Train Epoch: 2 [3200/4575 (70%)]\tLoss: 3.498532\n",
      "Train Epoch: 2 [3840/4575 (84%)]\tLoss: 3.213641\n",
      "Train Epoch: 2 [4480/4575 (98%)]\tLoss: 3.289824\n",
      "Epoch: 2, Training Accuracy: 19.32%\n",
      "Epoch: 2, Testing Accuracy: 21.23%\n",
      "Epoch: 2, Sub-Testing Accuracy: 3.19%\n",
      "Train Epoch: 3 [0/4575 (0%)]\tLoss: 3.233498\n",
      "Train Epoch: 3 [640/4575 (14%)]\tLoss: 3.117480\n",
      "Train Epoch: 3 [1280/4575 (28%)]\tLoss: 3.594040\n",
      "Train Epoch: 3 [1920/4575 (42%)]\tLoss: 3.131511\n",
      "Train Epoch: 3 [2560/4575 (56%)]\tLoss: 2.640499\n",
      "Train Epoch: 3 [3200/4575 (70%)]\tLoss: 3.262707\n",
      "Train Epoch: 3 [3840/4575 (84%)]\tLoss: 2.832327\n",
      "Train Epoch: 3 [4480/4575 (98%)]\tLoss: 2.645784\n",
      "Epoch: 3, Training Accuracy: 24.07%\n",
      "Epoch: 3, Testing Accuracy: 30.08%\n",
      "Epoch: 3, Sub-Testing Accuracy: 6.37%\n",
      "Train Epoch: 4 [0/4575 (0%)]\tLoss: 2.708734\n",
      "Train Epoch: 4 [640/4575 (14%)]\tLoss: 2.520153\n",
      "Train Epoch: 4 [1280/4575 (28%)]\tLoss: 3.105467\n",
      "Train Epoch: 4 [1920/4575 (42%)]\tLoss: 2.974804\n",
      "Train Epoch: 4 [2560/4575 (56%)]\tLoss: 2.636714\n",
      "Train Epoch: 4 [3200/4575 (70%)]\tLoss: 2.448608\n",
      "Train Epoch: 4 [3840/4575 (84%)]\tLoss: 2.797093\n",
      "Train Epoch: 4 [4480/4575 (98%)]\tLoss: 3.067933\n",
      "Epoch: 4, Training Accuracy: 28.61%\n",
      "Epoch: 4, Testing Accuracy: 23.97%\n",
      "Epoch: 4, Sub-Testing Accuracy: 5.58%\n",
      "Train Epoch: 5 [0/4575 (0%)]\tLoss: 2.888856\n",
      "Train Epoch: 5 [640/4575 (14%)]\tLoss: 2.722419\n",
      "Train Epoch: 5 [1280/4575 (28%)]\tLoss: 2.326990\n",
      "Train Epoch: 5 [1920/4575 (42%)]\tLoss: 2.465881\n",
      "Train Epoch: 5 [2560/4575 (56%)]\tLoss: 3.142625\n",
      "Train Epoch: 5 [3200/4575 (70%)]\tLoss: 2.409998\n",
      "Train Epoch: 5 [3840/4575 (84%)]\tLoss: 2.787556\n",
      "Train Epoch: 5 [4480/4575 (98%)]\tLoss: 2.582248\n",
      "Epoch: 5, Training Accuracy: 31.23%\n",
      "Epoch: 5, Testing Accuracy: 29.29%\n",
      "Epoch: 5, Sub-Testing Accuracy: 6.37%\n",
      "Train Epoch: 6 [0/4575 (0%)]\tLoss: 2.031951\n",
      "Train Epoch: 6 [640/4575 (14%)]\tLoss: 2.073701\n",
      "Train Epoch: 6 [1280/4575 (28%)]\tLoss: 2.425895\n",
      "Train Epoch: 6 [1920/4575 (42%)]\tLoss: 2.829083\n",
      "Train Epoch: 6 [2560/4575 (56%)]\tLoss: 1.893910\n",
      "Train Epoch: 6 [3200/4575 (70%)]\tLoss: 2.529027\n",
      "Train Epoch: 6 [3840/4575 (84%)]\tLoss: 2.380002\n",
      "Train Epoch: 6 [4480/4575 (98%)]\tLoss: 2.265313\n",
      "Epoch: 6, Training Accuracy: 35.15%\n",
      "Epoch: 6, Testing Accuracy: 36.94%\n",
      "Epoch: 6, Sub-Testing Accuracy: 6.37%\n",
      "Train Epoch: 7 [0/4575 (0%)]\tLoss: 2.714666\n",
      "Train Epoch: 7 [640/4575 (14%)]\tLoss: 2.596200\n",
      "Train Epoch: 7 [1280/4575 (28%)]\tLoss: 2.664594\n",
      "Train Epoch: 7 [1920/4575 (42%)]\tLoss: 2.444977\n",
      "Train Epoch: 7 [2560/4575 (56%)]\tLoss: 2.216847\n",
      "Train Epoch: 7 [3200/4575 (70%)]\tLoss: 2.004556\n",
      "Train Epoch: 7 [3840/4575 (84%)]\tLoss: 2.170023\n",
      "Train Epoch: 7 [4480/4575 (98%)]\tLoss: 2.802314\n",
      "Epoch: 7, Training Accuracy: 37.81%\n",
      "Epoch: 7, Testing Accuracy: 39.92%\n",
      "Epoch: 7, Sub-Testing Accuracy: 7.97%\n",
      "Train Epoch: 8 [0/4575 (0%)]\tLoss: 2.588488\n",
      "Train Epoch: 8 [640/4575 (14%)]\tLoss: 2.729141\n",
      "Train Epoch: 8 [1280/4575 (28%)]\tLoss: 2.053703\n",
      "Train Epoch: 8 [1920/4575 (42%)]\tLoss: 2.231103\n",
      "Train Epoch: 8 [2560/4575 (56%)]\tLoss: 2.749746\n",
      "Train Epoch: 8 [3200/4575 (70%)]\tLoss: 2.896111\n",
      "Train Epoch: 8 [3840/4575 (84%)]\tLoss: 2.675181\n",
      "Train Epoch: 8 [4480/4575 (98%)]\tLoss: 2.043312\n",
      "Epoch: 8, Training Accuracy: 40.44%\n",
      "Epoch: 8, Testing Accuracy: 42.18%\n",
      "Epoch: 8, Sub-Testing Accuracy: 7.17%\n",
      "Train Epoch: 9 [0/4575 (0%)]\tLoss: 1.970552\n",
      "Train Epoch: 9 [640/4575 (14%)]\tLoss: 2.424192\n",
      "Train Epoch: 9 [1280/4575 (28%)]\tLoss: 2.257082\n",
      "Train Epoch: 9 [1920/4575 (42%)]\tLoss: 1.925489\n",
      "Train Epoch: 9 [2560/4575 (56%)]\tLoss: 3.065490\n",
      "Train Epoch: 9 [3200/4575 (70%)]\tLoss: 2.388527\n",
      "Train Epoch: 9 [3840/4575 (84%)]\tLoss: 2.293987\n",
      "Train Epoch: 9 [4480/4575 (98%)]\tLoss: 2.158252\n",
      "Epoch: 9, Training Accuracy: 39.52%\n",
      "Epoch: 9, Testing Accuracy: 44.72%\n",
      "Epoch: 9, Sub-Testing Accuracy: 7.57%\n",
      "Train Epoch: 10 [0/4575 (0%)]\tLoss: 1.944839\n",
      "Train Epoch: 10 [640/4575 (14%)]\tLoss: 1.703080\n",
      "Train Epoch: 10 [1280/4575 (28%)]\tLoss: 1.804072\n",
      "Train Epoch: 10 [1920/4575 (42%)]\tLoss: 2.510679\n",
      "Train Epoch: 10 [2560/4575 (56%)]\tLoss: 1.661571\n",
      "Train Epoch: 10 [3200/4575 (70%)]\tLoss: 1.775654\n",
      "Train Epoch: 10 [3840/4575 (84%)]\tLoss: 2.085744\n",
      "Train Epoch: 10 [4480/4575 (98%)]\tLoss: 2.370461\n",
      "Epoch: 10, Training Accuracy: 43.06%\n",
      "Epoch: 10, Testing Accuracy: 43.97%\n",
      "Epoch: 10, Sub-Testing Accuracy: 7.57%\n",
      "Train Epoch: 11 [0/4575 (0%)]\tLoss: 2.391542\n",
      "Train Epoch: 11 [640/4575 (14%)]\tLoss: 1.667402\n",
      "Train Epoch: 11 [1280/4575 (28%)]\tLoss: 2.047100\n",
      "Train Epoch: 11 [1920/4575 (42%)]\tLoss: 1.981346\n",
      "Train Epoch: 11 [2560/4575 (56%)]\tLoss: 2.341647\n",
      "Train Epoch: 11 [3200/4575 (70%)]\tLoss: 1.886835\n",
      "Train Epoch: 11 [3840/4575 (84%)]\tLoss: 1.289697\n",
      "Train Epoch: 11 [4480/4575 (98%)]\tLoss: 1.690749\n",
      "Epoch: 11, Training Accuracy: 43.50%\n",
      "Epoch: 11, Testing Accuracy: 42.02%\n",
      "Epoch: 11, Sub-Testing Accuracy: 9.16%\n",
      "Train Epoch: 12 [0/4575 (0%)]\tLoss: 1.816537\n",
      "Train Epoch: 12 [640/4575 (14%)]\tLoss: 1.899466\n",
      "Train Epoch: 12 [1280/4575 (28%)]\tLoss: 1.961850\n",
      "Train Epoch: 12 [1920/4575 (42%)]\tLoss: 1.855942\n",
      "Train Epoch: 12 [2560/4575 (56%)]\tLoss: 2.013033\n",
      "Train Epoch: 12 [3200/4575 (70%)]\tLoss: 2.037074\n",
      "Train Epoch: 12 [3840/4575 (84%)]\tLoss: 2.061922\n",
      "Train Epoch: 12 [4480/4575 (98%)]\tLoss: 1.517333\n",
      "Epoch: 12, Training Accuracy: 47.06%\n",
      "Epoch: 12, Testing Accuracy: 47.90%\n",
      "Epoch: 12, Sub-Testing Accuracy: 9.16%\n",
      "Train Epoch: 13 [0/4575 (0%)]\tLoss: 1.655248\n",
      "Train Epoch: 13 [640/4575 (14%)]\tLoss: 2.125715\n",
      "Train Epoch: 13 [1280/4575 (28%)]\tLoss: 2.347677\n",
      "Train Epoch: 13 [1920/4575 (42%)]\tLoss: 1.969243\n",
      "Train Epoch: 13 [2560/4575 (56%)]\tLoss: 2.104787\n",
      "Train Epoch: 13 [3200/4575 (70%)]\tLoss: 2.208440\n",
      "Train Epoch: 13 [3840/4575 (84%)]\tLoss: 2.169672\n",
      "Train Epoch: 13 [4480/4575 (98%)]\tLoss: 2.234316\n",
      "Epoch: 13, Training Accuracy: 47.04%\n",
      "Epoch: 13, Testing Accuracy: 48.45%\n",
      "Epoch: 13, Sub-Testing Accuracy: 8.76%\n",
      "Train Epoch: 14 [0/4575 (0%)]\tLoss: 2.259260\n",
      "Train Epoch: 14 [640/4575 (14%)]\tLoss: 1.402268\n",
      "Train Epoch: 14 [1280/4575 (28%)]\tLoss: 1.961509\n",
      "Train Epoch: 14 [1920/4575 (42%)]\tLoss: 1.621163\n",
      "Train Epoch: 14 [2560/4575 (56%)]\tLoss: 1.944312\n",
      "Train Epoch: 14 [3200/4575 (70%)]\tLoss: 1.665578\n",
      "Train Epoch: 14 [3840/4575 (84%)]\tLoss: 1.643133\n",
      "Train Epoch: 14 [4480/4575 (98%)]\tLoss: 1.958859\n",
      "Epoch: 14, Training Accuracy: 48.44%\n",
      "Epoch: 14, Testing Accuracy: 48.25%\n",
      "Epoch: 14, Sub-Testing Accuracy: 9.56%\n",
      "Train Epoch: 15 [0/4575 (0%)]\tLoss: 1.379629\n",
      "Train Epoch: 15 [640/4575 (14%)]\tLoss: 1.497403\n",
      "Train Epoch: 15 [1280/4575 (28%)]\tLoss: 1.880012\n",
      "Train Epoch: 15 [1920/4575 (42%)]\tLoss: 1.744598\n",
      "Train Epoch: 15 [2560/4575 (56%)]\tLoss: 1.782435\n",
      "Train Epoch: 15 [3200/4575 (70%)]\tLoss: 1.454293\n",
      "Train Epoch: 15 [3840/4575 (84%)]\tLoss: 1.687014\n",
      "Train Epoch: 15 [4480/4575 (98%)]\tLoss: 2.072794\n",
      "Epoch: 15, Training Accuracy: 48.15%\n",
      "Epoch: 15, Testing Accuracy: 46.75%\n",
      "Epoch: 15, Sub-Testing Accuracy: 7.17%\n",
      "Train Epoch: 16 [0/4575 (0%)]\tLoss: 1.666362\n",
      "Train Epoch: 16 [640/4575 (14%)]\tLoss: 1.630904\n",
      "Train Epoch: 16 [1280/4575 (28%)]\tLoss: 1.600402\n",
      "Train Epoch: 16 [1920/4575 (42%)]\tLoss: 1.713795\n",
      "Train Epoch: 16 [2560/4575 (56%)]\tLoss: 2.381140\n",
      "Train Epoch: 16 [3200/4575 (70%)]\tLoss: 1.326938\n",
      "Train Epoch: 16 [3840/4575 (84%)]\tLoss: 1.922226\n",
      "Train Epoch: 16 [4480/4575 (98%)]\tLoss: 1.569339\n",
      "Epoch: 16, Training Accuracy: 50.51%\n",
      "Epoch: 16, Testing Accuracy: 50.20%\n",
      "Epoch: 16, Sub-Testing Accuracy: 9.16%\n",
      "Train Epoch: 17 [0/4575 (0%)]\tLoss: 1.463828\n",
      "Train Epoch: 17 [640/4575 (14%)]\tLoss: 1.805930\n",
      "Train Epoch: 17 [1280/4575 (28%)]\tLoss: 1.764009\n",
      "Train Epoch: 17 [1920/4575 (42%)]\tLoss: 2.036553\n",
      "Train Epoch: 17 [2560/4575 (56%)]\tLoss: 2.263013\n",
      "Train Epoch: 17 [3200/4575 (70%)]\tLoss: 1.846962\n",
      "Train Epoch: 17 [3840/4575 (84%)]\tLoss: 1.405848\n",
      "Train Epoch: 17 [4480/4575 (98%)]\tLoss: 1.323093\n",
      "Epoch: 17, Training Accuracy: 51.43%\n",
      "Epoch: 17, Testing Accuracy: 49.92%\n",
      "Epoch: 17, Sub-Testing Accuracy: 8.37%\n",
      "Train Epoch: 18 [0/4575 (0%)]\tLoss: 1.484453\n",
      "Train Epoch: 18 [640/4575 (14%)]\tLoss: 2.488121\n",
      "Train Epoch: 18 [1280/4575 (28%)]\tLoss: 1.720992\n",
      "Train Epoch: 18 [1920/4575 (42%)]\tLoss: 1.598826\n",
      "Train Epoch: 18 [2560/4575 (56%)]\tLoss: 1.459222\n",
      "Train Epoch: 18 [3200/4575 (70%)]\tLoss: 1.770344\n",
      "Train Epoch: 18 [3840/4575 (84%)]\tLoss: 2.173491\n",
      "Train Epoch: 18 [4480/4575 (98%)]\tLoss: 2.100070\n",
      "Epoch: 18, Training Accuracy: 53.16%\n",
      "Epoch: 18, Testing Accuracy: 52.94%\n",
      "Epoch: 18, Sub-Testing Accuracy: 7.57%\n",
      "Train Epoch: 19 [0/4575 (0%)]\tLoss: 1.580413\n",
      "Train Epoch: 19 [640/4575 (14%)]\tLoss: 1.485010\n",
      "Train Epoch: 19 [1280/4575 (28%)]\tLoss: 1.964011\n",
      "Train Epoch: 19 [1920/4575 (42%)]\tLoss: 1.563351\n",
      "Train Epoch: 19 [2560/4575 (56%)]\tLoss: 1.593930\n",
      "Train Epoch: 19 [3200/4575 (70%)]\tLoss: 1.835303\n",
      "Train Epoch: 19 [3840/4575 (84%)]\tLoss: 1.272514\n",
      "Train Epoch: 19 [4480/4575 (98%)]\tLoss: 1.286892\n",
      "Epoch: 19, Training Accuracy: 54.89%\n",
      "Epoch: 19, Testing Accuracy: 53.17%\n",
      "Epoch: 19, Sub-Testing Accuracy: 9.96%\n",
      "Train Epoch: 20 [0/4575 (0%)]\tLoss: 1.317278\n",
      "Train Epoch: 20 [640/4575 (14%)]\tLoss: 1.856788\n",
      "Train Epoch: 20 [1280/4575 (28%)]\tLoss: 1.658566\n",
      "Train Epoch: 20 [1920/4575 (42%)]\tLoss: 1.855632\n",
      "Train Epoch: 20 [2560/4575 (56%)]\tLoss: 1.429895\n",
      "Train Epoch: 20 [3200/4575 (70%)]\tLoss: 2.128531\n",
      "Train Epoch: 20 [3840/4575 (84%)]\tLoss: 1.633604\n",
      "Train Epoch: 20 [4480/4575 (98%)]\tLoss: 1.654034\n",
      "Epoch: 20, Training Accuracy: 54.51%\n",
      "Epoch: 20, Testing Accuracy: 56.90%\n",
      "Epoch: 20, Sub-Testing Accuracy: 11.55%\n",
      "Training and evaluation finished in: 735.5931348800659 sec.\n"
     ]
    }
   ],
   "source": [
    "dataAugTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea480c-237c-4b77-856f-b03757638882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
